import type { ModelInfo } from "../model.js"

export type AimlApiModelId = keyof typeof aimlApiModels

export const aimlApiDefaultModelId: AimlApiModelId = "gpt-4o"

export const aimlApiModels = {
    "qwen-max": {
        maxTokens: 8192,
        contextWindow: 32768,
        supportsImages: true,
        supportsPromptCache: true,
        supportsNativeTools: true,
        defaultToolProtocol: "native",
        inputPrice: 0,
        outputPrice: 0,
        description: "Qwen Max - Advanced reasoning model.",
    },
    "qwen-plus": {
        maxTokens: 8192,
        contextWindow: 32768,
        supportsImages: true,
        supportsPromptCache: true,
        supportsNativeTools: true,
        defaultToolProtocol: "native",
        inputPrice: 0,
        outputPrice: 0,
        description: "Qwen Plus - Balanced performance model.",
    },
    "qwen-turbo": {
        maxTokens: 8192,
        contextWindow: 32768,
        supportsImages: true,
        supportsPromptCache: false,
        supportsNativeTools: true,
        defaultToolProtocol: "native",
        inputPrice: 0,
        outputPrice: 0,
        description: "Qwen Turbo - Fast and efficient.",
    },
    "gpt-4o": {
        maxTokens: 4096,
        contextWindow: 128000,
        supportsImages: true,
        supportsPromptCache: false,
        supportsNativeTools: true,
        defaultToolProtocol: "native",
        inputPrice: 0,
        outputPrice: 0,
        description: "GPT-4o via AIMLAPI.",
    },
    "claude-3-5-sonnet-20241022": {
        maxTokens: 8192,
        contextWindow: 200000,
        supportsImages: true,
        supportsPromptCache: false,
        supportsNativeTools: true,
        defaultToolProtocol: "native",
        inputPrice: 0,
        outputPrice: 0,
        description: "Claude 3.5 Sonnet via AIMLAPI.",
    },
    "gemini-2.0-flash-exp": {
        maxTokens: 8192,
        contextWindow: 1000000,
        supportsImages: true,
        supportsPromptCache: false,
        supportsNativeTools: true,
        defaultToolProtocol: "native",
        inputPrice: 0,
        outputPrice: 0,
        description: "Gemini 2.0 Flash Exp via AIMLAPI.",
    },
    "deepseek-chat": {
        maxTokens: 4096,
        contextWindow: 32768,
        supportsImages: false,
        supportsPromptCache: false,
        supportsNativeTools: true,
        defaultToolProtocol: "native",
        inputPrice: 0,
        outputPrice: 0,
        description: "DeepSeek V3 via AIMLAPI.",
    },
    "deepseek-reasoner": {
        maxTokens: 4096,
        contextWindow: 32768,
        supportsImages: false,
        supportsPromptCache: false,
        supportsNativeTools: true,
        defaultToolProtocol: "native",
        preserveReasoning: true,
        inputPrice: 0,
        outputPrice: 0,
        description: "DeepSeek R1 via AIMLAPI.",
    },
    // Add more as needed or dynamic loading
} as const satisfies Record<string, ModelInfo>
